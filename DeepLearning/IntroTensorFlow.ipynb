{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n",
      "(1000, 1)\n",
      "[[-1.8452498  -4.34427029]\n",
      " [-1.66360532  6.41772426]]\n"
     ]
    }
   ],
   "source": [
    "observations = 1000\n",
    "\n",
    "xs = np.random.uniform(low=-10,high=10,size=(observations,1))\n",
    "zs = np.random.uniform(-10,10,(observations,1))\n",
    "print(xs.shape)\n",
    "print(zs.shape)\n",
    "\n",
    "generated_inputs = np.column_stack((xs,zs))\n",
    "print(generated_inputs[:2])\n",
    "\n",
    "noise = np.random.uniform(-1,1,(observations,1))\n",
    "\n",
    "generated_targets = 2*xs - 3*zs + 5 + noise\n",
    "\n",
    "np.savez('TF_intro',inputs=generated_inputs, targets=generated_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solving with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load('TF_intro.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples\n",
      "Epoch 1/100\n",
      "1000/1000 - 1s - loss: 20.4552\n",
      "Epoch 2/100\n",
      "1000/1000 - 0s - loss: 1.2782\n",
      "Epoch 3/100\n",
      "1000/1000 - 0s - loss: 0.4331\n",
      "Epoch 4/100\n",
      "1000/1000 - 0s - loss: 0.3843\n",
      "Epoch 5/100\n",
      "1000/1000 - 0s - loss: 0.3988\n",
      "Epoch 6/100\n",
      "1000/1000 - 0s - loss: 0.4173\n",
      "Epoch 7/100\n",
      "1000/1000 - 0s - loss: 0.3750\n",
      "Epoch 8/100\n",
      "1000/1000 - 0s - loss: 0.4043\n",
      "Epoch 9/100\n",
      "1000/1000 - 0s - loss: 0.3827\n",
      "Epoch 10/100\n",
      "1000/1000 - 0s - loss: 0.3841\n",
      "Epoch 11/100\n",
      "1000/1000 - 0s - loss: 0.3688\n",
      "Epoch 12/100\n",
      "1000/1000 - 0s - loss: 0.4039\n",
      "Epoch 13/100\n",
      "1000/1000 - 0s - loss: 0.3691\n",
      "Epoch 14/100\n",
      "1000/1000 - 0s - loss: 0.4167\n",
      "Epoch 15/100\n",
      "1000/1000 - 0s - loss: 0.3693\n",
      "Epoch 16/100\n",
      "1000/1000 - 0s - loss: 0.3768\n",
      "Epoch 17/100\n",
      "1000/1000 - 0s - loss: 0.3663\n",
      "Epoch 18/100\n",
      "1000/1000 - 0s - loss: 0.3809\n",
      "Epoch 19/100\n",
      "1000/1000 - 0s - loss: 0.3712\n",
      "Epoch 20/100\n",
      "1000/1000 - 0s - loss: 0.3879\n",
      "Epoch 21/100\n",
      "1000/1000 - 0s - loss: 0.3947\n",
      "Epoch 22/100\n",
      "1000/1000 - 0s - loss: 0.3711\n",
      "Epoch 23/100\n",
      "1000/1000 - 0s - loss: 0.3820\n",
      "Epoch 24/100\n",
      "1000/1000 - 0s - loss: 0.4077\n",
      "Epoch 25/100\n",
      "1000/1000 - 0s - loss: 0.3941\n",
      "Epoch 26/100\n",
      "1000/1000 - 0s - loss: 0.3993\n",
      "Epoch 27/100\n",
      "1000/1000 - 0s - loss: 0.4263\n",
      "Epoch 28/100\n",
      "1000/1000 - 0s - loss: 0.3865\n",
      "Epoch 29/100\n",
      "1000/1000 - 0s - loss: 0.4014\n",
      "Epoch 30/100\n",
      "1000/1000 - 0s - loss: 0.3758\n",
      "Epoch 31/100\n",
      "1000/1000 - 0s - loss: 0.3947\n",
      "Epoch 32/100\n",
      "1000/1000 - 0s - loss: 0.4552\n",
      "Epoch 33/100\n",
      "1000/1000 - 0s - loss: 0.3902\n",
      "Epoch 34/100\n",
      "1000/1000 - 0s - loss: 0.3682\n",
      "Epoch 35/100\n",
      "1000/1000 - 0s - loss: 0.3819\n",
      "Epoch 36/100\n",
      "1000/1000 - 0s - loss: 0.3720\n",
      "Epoch 37/100\n",
      "1000/1000 - 0s - loss: 0.3751\n",
      "Epoch 38/100\n",
      "1000/1000 - 0s - loss: 0.3741\n",
      "Epoch 39/100\n",
      "1000/1000 - 0s - loss: 0.3909\n",
      "Epoch 40/100\n",
      "1000/1000 - 0s - loss: 0.3988\n",
      "Epoch 41/100\n",
      "1000/1000 - 0s - loss: 0.3769\n",
      "Epoch 42/100\n",
      "1000/1000 - 0s - loss: 0.4061\n",
      "Epoch 43/100\n",
      "1000/1000 - 0s - loss: 0.3880\n",
      "Epoch 44/100\n",
      "1000/1000 - 0s - loss: 0.4174\n",
      "Epoch 45/100\n",
      "1000/1000 - 0s - loss: 0.3922\n",
      "Epoch 46/100\n",
      "1000/1000 - 0s - loss: 0.3672\n",
      "Epoch 47/100\n",
      "1000/1000 - 0s - loss: 0.3835\n",
      "Epoch 48/100\n",
      "1000/1000 - 0s - loss: 0.3997\n",
      "Epoch 49/100\n",
      "1000/1000 - 0s - loss: 0.3747\n",
      "Epoch 50/100\n",
      "1000/1000 - 0s - loss: 0.3923\n",
      "Epoch 51/100\n",
      "1000/1000 - 0s - loss: 0.3945\n",
      "Epoch 52/100\n",
      "1000/1000 - 0s - loss: 0.3804\n",
      "Epoch 53/100\n",
      "1000/1000 - 0s - loss: 0.3744\n",
      "Epoch 54/100\n",
      "1000/1000 - 0s - loss: 0.4073\n",
      "Epoch 55/100\n",
      "1000/1000 - 0s - loss: 0.3859\n",
      "Epoch 56/100\n",
      "1000/1000 - 0s - loss: 0.4055\n",
      "Epoch 57/100\n",
      "1000/1000 - 0s - loss: 0.4453\n",
      "Epoch 58/100\n",
      "1000/1000 - 0s - loss: 0.3950\n",
      "Epoch 59/100\n",
      "1000/1000 - 0s - loss: 0.4175\n",
      "Epoch 60/100\n",
      "1000/1000 - 0s - loss: 0.3932\n",
      "Epoch 61/100\n",
      "1000/1000 - 0s - loss: 0.3721\n",
      "Epoch 62/100\n",
      "1000/1000 - 0s - loss: 0.3878\n",
      "Epoch 63/100\n",
      "1000/1000 - 0s - loss: 0.3729\n",
      "Epoch 64/100\n",
      "1000/1000 - 0s - loss: 0.3878\n",
      "Epoch 65/100\n",
      "1000/1000 - 0s - loss: 0.3768\n",
      "Epoch 66/100\n",
      "1000/1000 - 0s - loss: 0.3607\n",
      "Epoch 67/100\n",
      "1000/1000 - 0s - loss: 0.3696\n",
      "Epoch 68/100\n",
      "1000/1000 - 0s - loss: 0.4158\n",
      "Epoch 69/100\n",
      "1000/1000 - 0s - loss: 0.3912\n",
      "Epoch 70/100\n",
      "1000/1000 - 0s - loss: 0.3947\n",
      "Epoch 71/100\n",
      "1000/1000 - 0s - loss: 0.4437\n",
      "Epoch 72/100\n",
      "1000/1000 - 0s - loss: 0.3744\n",
      "Epoch 73/100\n",
      "1000/1000 - 0s - loss: 0.3816\n",
      "Epoch 74/100\n",
      "1000/1000 - 0s - loss: 0.4113\n",
      "Epoch 75/100\n",
      "1000/1000 - 0s - loss: 0.3841\n",
      "Epoch 76/100\n",
      "1000/1000 - 0s - loss: 0.4016\n",
      "Epoch 77/100\n",
      "1000/1000 - 0s - loss: 0.3988\n",
      "Epoch 78/100\n",
      "1000/1000 - 0s - loss: 0.4007\n",
      "Epoch 79/100\n",
      "1000/1000 - 0s - loss: 0.3890\n",
      "Epoch 80/100\n",
      "1000/1000 - 0s - loss: 0.3899\n",
      "Epoch 81/100\n",
      "1000/1000 - 0s - loss: 0.4096\n",
      "Epoch 82/100\n",
      "1000/1000 - 0s - loss: 0.3859\n",
      "Epoch 83/100\n",
      "1000/1000 - 0s - loss: 0.4187\n",
      "Epoch 84/100\n",
      "1000/1000 - 0s - loss: 0.4133\n",
      "Epoch 85/100\n",
      "1000/1000 - 0s - loss: 0.4079\n",
      "Epoch 86/100\n",
      "1000/1000 - 0s - loss: 0.3787\n",
      "Epoch 87/100\n",
      "1000/1000 - 0s - loss: 0.3997\n",
      "Epoch 88/100\n",
      "1000/1000 - 0s - loss: 0.3883\n",
      "Epoch 89/100\n",
      "1000/1000 - 0s - loss: 0.4136\n",
      "Epoch 90/100\n",
      "1000/1000 - 0s - loss: 0.3799\n",
      "Epoch 91/100\n",
      "1000/1000 - 0s - loss: 0.3881\n",
      "Epoch 92/100\n",
      "1000/1000 - 0s - loss: 0.3630\n",
      "Epoch 93/100\n",
      "1000/1000 - 0s - loss: 0.4192\n",
      "Epoch 94/100\n",
      "1000/1000 - 0s - loss: 0.3914\n",
      "Epoch 95/100\n",
      "1000/1000 - 0s - loss: 0.3816\n",
      "Epoch 96/100\n",
      "1000/1000 - 0s - loss: 0.4619\n",
      "Epoch 97/100\n",
      "1000/1000 - 0s - loss: 0.3784\n",
      "Epoch 98/100\n",
      "1000/1000 - 0s - loss: 0.4179\n",
      "Epoch 99/100\n",
      "1000/1000 - 0s - loss: 0.3869\n",
      "Epoch 100/100\n",
      "1000/1000 - 0s - loss: 0.3989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a419667bc8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 2\n",
    "output_size = 1\n",
    "\n",
    "# model\n",
    "'''\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Dense(output_size)  \n",
    "                            ])\n",
    "'''\n",
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Dense(output_size,\n",
    "                                                    kernel_initializer =tf.random_uniform_initializer(minval=-0.1,maxval=0.1),\n",
    "                                                    bias_initializer = tf.random_uniform_initializer(minval=-0.1,maxval=0.1)\n",
    "                            )  \n",
    "                            ])\n",
    "# object function = loss, optimization\n",
    "\n",
    "custom_optimizer = tf.keras.optimizers.SGD(learning_rate=0.02)\n",
    "#model.compile(optimizer ='sgd',loss='mean_squared_error')    # sgd => Stochastic Gradient Descent\n",
    "\n",
    "model.compile(optimizer =custom_optimizer,loss='mean_squared_error')\n",
    "# fitting the model to data\n",
    "model.fit(training_data['inputs'],training_data['targets'],epochs=100,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output = np.dot(inputs,weights) + bias\n",
    "* `tf.keras.layers.Dense(output size)` takes the inputs provided to the model and calculates the dot product of the inputs and the weights and adds the bias -> also applies activation function(optional)\n",
    "* `model.compile(optimizer,loss)` configures the model for training -> l2-norm loss = Least sum of squares(least sum of squared error)\n",
    "* `Epoch` = iteration over the full dataset\n",
    "* `verbose` = 0(stands for 'silent' or no output about the training is displayed), 1(for 'progress bar'), 2 (for 'one line per epoch')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.9765515],\n",
       "        [-3.076067 ]], dtype=float32), array([5.0197763], dtype=float32)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted weights = [1.9765515],[-3.076067]\n",
      "Predicted bias =  [5.0197763]\n"
     ]
    }
   ],
   "source": [
    "weights = model.layers[0].get_weights()[0]\n",
    "bias = model.layers[0].get_weights()[1]\n",
    "print(f\"Predicted weights = {weights[0]},{weights[1]}\")\n",
    "print(\"Predicted bias = \",bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the outputs (make predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'round'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-e5e72b376ac0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredicted_values\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'inputs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpredicted_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'round'"
     ]
    }
   ],
   "source": [
    "predicted_values =model.predict_on_batch(training_data['inputs']).round(1)\n",
    "predicted_values[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 14.7],\n",
       "       [-18. ],\n",
       "       [  4.1],\n",
       "       [ 10.8],\n",
       "       [ 49.4]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_values = np.array(model.predict_on_batch(training_data['inputs']))\n",
    "predicted_values.round(1)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 14.9],\n",
       "       [-17.3],\n",
       "       [  3.5],\n",
       "       [  9.7],\n",
       "       [ 47.9]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# targets/ original\n",
    "training_data['targets'].round(1)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PLotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(np.squeeze(model.predict_on_batch(training_data['inputs'])),np.squeeze(training_data['targets']))\n",
    "plt.xlabel('outputs')\n",
    "plt.ylabel('targets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MNIST Data Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Steps***\n",
    "1. Prepare our data and preprocess it. Create training, validation and test datasets\n",
    "2. Outline the model and choose the activate functions\n",
    "3. Set the appropriate advanced optimizers and the loss function\n",
    "4. Make it learn\n",
    "5. Test the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_datasets,mnist_info = tfds.load(name='mnist',with_info=True,as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train,mnist_test = mnist_datasets['train'],mnist_datasets['test']\n",
    "\n",
    "# Validation percentage\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "# casts a variable into a given type\n",
    "num_validation_samples = tf.cast(num_validation_samples,tf.int64)\n",
    "\n",
    "# test\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples,tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the datasets\n",
    "def scale(image,label):\n",
    "    image = tf.cast(image,tf.float32)\n",
    "    image /=255.   # . represent the final output is float\n",
    "    return image, label    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_and_validation_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "BUFFER_SIZE = 10000 # taking 10000 samples\n",
    "\n",
    "shuffle_train_and_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n",
    "# Validation datasets\n",
    "validation_data = shuffle_train_and_validation_data.take(num_validation_samples)\n",
    "# train datasets\n",
    "train_data = shuffle_train_and_validation_data.skip(num_validation_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * if buffer_size =1 , no shuffling will actually happen\n",
    "* if butter_size >=num_samples, shuffling will happen at once(uniformly)\n",
    "* if 1< buffer_size < num_samples, we will be optimizing the computational power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batching for backward propagation\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "test_data = test_data.batch(num_test_samples)\n",
    "\n",
    "validation_inputs, validation_targets = next(iter(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `iter()` creates an object which can be iterated one element at a time(e.g. in a for loop or while loop)\n",
    "* `next()` loads the next element of an iterable object\n",
    "\n",
    "> * batch_size = 1 = Stochastic gradient descent(SGD)\n",
    "* batch_size = # samples = (single batch) GD\n",
    "* 1< batch _size < # samples = mini-batch GD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model\n",
    "outline the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "output_size = 10\n",
    "hidden_layer_size = 100 #50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-bab2a5f864fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model = tf.keras.Sequential([\n\u001b[1;32m----> 2\u001b[1;33m                             \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m                             \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_layer_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                             \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_layer_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                             \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Flatten(input_size(28,28,1)),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "                            tf.keras.layers.Dense(output_size,activation='softmax')\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.keras.layers.Flattten(original shape)` transforms((Flattens)) a tensor into a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "                            tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "                            tf.keras.layers.Dense(hidden_layer_size,activation='relu'),\n",
    "                            tf.keras.layers.Dense(output_size,activation='softmax')\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose the optimizer and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***loss function***\n",
    "* `categorical_crossentropy` -> expects that you've one-hot encoded the targets\n",
    "* `sparse_catergorical_crossentropy` -> applies one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`batch_size` or `steps` is required for `Tensor` or `NumPy` input data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-a64cd5f1233a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\deepLearning\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deepLearning\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m           distribution_strategy=strategy)\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deepLearning\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    562\u001b[0m                                     \u001b[0mclass_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m                                     \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m                                     distribution_strategy=distribution_strategy)\n\u001b[0m\u001b[0;32m    565\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m       raise ValueError('`validation_steps` should not be specified if '\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deepLearning\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    604\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    607\u001b[0m   \u001b[1;31m# As a fallback for the data type that does not work with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m   \u001b[1;31m# _standardize_user_data, use the _prepare_model_with_inputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deepLearning\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m       raise ValueError(\n\u001b[1;32m--> 254\u001b[1;33m           \u001b[1;34m\"`batch_size` or `steps` is required for `Tensor` or `NumPy`\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m           \" input data.\")\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `batch_size` or `steps` is required for `Tensor` or `NumPy` input data."
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "\n",
    "model.fit(train_data,epochs=NUM_EPOCHS,validation_data=(validation_inputs,validation_targets),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 10s - loss: 0.3181 - accuracy: 0.9095 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "540/540 - 9s - loss: 0.1329 - accuracy: 0.9599 - val_loss: 0.1309 - val_accuracy: 0.9618\n",
      "Epoch 3/5\n",
      "540/540 - 9s - loss: 0.0943 - accuracy: 0.9713 - val_loss: 0.0918 - val_accuracy: 0.9743\n",
      "Epoch 4/5\n",
      "540/540 - 9s - loss: 0.0721 - accuracy: 0.9778 - val_loss: 0.0896 - val_accuracy: 0.9737\n",
      "Epoch 5/5\n",
      "540/540 - 10s - loss: 0.0585 - accuracy: 0.9820 - val_loss: 0.0716 - val_accuracy: 0.9787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a41ecea388>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "#must define validation steps\n",
    "VALIDATION_STEPS = num_validation_samples\n",
    "model.fit(train_data,epochs=NUM_EPOCHS,\n",
    "          validation_data=(validation_inputs,validation_targets),\n",
    "          validation_steps=VALIDATION_STEPS,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 644ms/step - loss: 0.0940 - accuracy: 0.9723\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test loss: {)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
